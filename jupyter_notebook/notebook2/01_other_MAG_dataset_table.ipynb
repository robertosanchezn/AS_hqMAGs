{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f67447-1520-4aa1-934d-c0a68571f54c",
   "metadata": {},
   "source": [
    "# Additional datasets from other studies\n",
    "This notebook describes the methods to access the genomes from other studies used in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9225c0c3-6d49-4a8c-85ee-d44a0966ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import gzip\n",
    "import shutil\n",
    "import requests, json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209fa532-129a-4f7d-a027-aba27fa6b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "## Path to BGCflow directory\n",
    "external_data_path = Path(\"/datadrive/bgcflow/data/external\")\n",
    "\n",
    "## Path to tables from other studies\n",
    "external_table_path = Path(\"../tables/other_studies\")\n",
    "external_table_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## Generate a config template for BGCflow\n",
    "df_bgcflow_template = pd.DataFrame(columns=[\"source\",\"organism\",\"genus\",\"species\",\"strain\",\"closest_placement_reference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "42a3ec64-5788-44da-b4bb-d0edd9d51523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# external files required to run the notebook\n",
    "# need to make this available in github!\n",
    "\n",
    "file_gtdb_archaea = Path(\"/datadrive/bgcflow/data/external/gtdbtk/gtdbtk.ar122.summary.tsv\")\n",
    "file_gtdb_bacteria = Path(\"/datadrive/bgcflow/data/external/gtdbtk/gtdbtk.bac120.summary.tsv\")\n",
    "file_gtdb_warning = Path(\"../tables/gtdbtk.warnings.log\")\n",
    "\n",
    "file_bickhart_checkm = Path(\"../tables/Bickhart_et_al_checkm_out.tsv\")\n",
    "file_christoph_ncbi = Path(\"../data/PRJNA449266_AssemblyDetails.txt\")\n",
    "file_chen_metadata = Path(\"../data/Table_1_Discovery of an Abundance of Biosynthetic Gene Clusters in Shark Bay Microbial Mats.XLSX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "208e6d94-1e39-4dd8-8aad-bf1f193f9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTDB dataset\n",
    "df_gtdb_archaea = pd.read_csv(file_gtdb_archaea, sep=\"\\t\")\n",
    "df_gtdb_bacteria = pd.read_csv(file_gtdb_bacteria, sep=\"\\t\")\n",
    "df_gtdb = pd.concat([df_gtdb_archaea, df_gtdb_bacteria])\n",
    "df_gtdb = df_gtdb.set_index(\"user_genome\", drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306767bf-2729-40d6-ae28-1fff123e18c3",
   "metadata": {},
   "source": [
    "## Dataset from Bickhart et al (464 genomes)\n",
    "The dataset can be accessed from https://zenodo.org/record/5138306/files/hifi_das.bin3c.bins.tar.gz. The dataset are then downloaded using wget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e5e9c-2430-4ffc-8091-96a17db7079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAG set for the Bickhart paper (464)\n",
    "! wget -P ../data https://zenodo.org/record/5138306/files/hifi_das.bin3c.bins.tar.gz?download=1 -nc\n",
    "! mv ../data/hifi_das.bin3c.bins.tar.gz\\?download\\=1 ../data/hifi_das.bin3c.bins.tar.gz\n",
    "! tar -xvzf ../data/hifi_das.bin3c.bins.tar.gz -C /target/directory\n",
    "tar = tarfile.open(\"sample.tar.gz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b154a-8f4d-4f48-9965-0ad2fa766d97",
   "metadata": {},
   "source": [
    "The metadata for the genomes are then cleaned to create a list of genomes that will be used in the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3bc1bd17-82dd-4fc0-86c9-a8e323e3da9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘../data/41587_2021_1130_MOESM3_ESM.xlsx’ already there; not retrieving.\n",
      "\n",
      "Bickhart et al has a total of 695 bins. Based on their methods, 353 are HQ.\n",
      "After running CheckM on the 695 bins, we get 286 HQ MAGs.\n",
      "These bins are classified as HQ in CheckM, but not in DAStools:\n",
      "['bin3c.119', 'bin3c.136', 'bin3c.169', 'bin3c.172', 'bin3c.181', 'bin3c.182', 'bin3c.183', 'bin3c.191', 'bin3c.212', 'bin3c.214', 'bin3c.219', 'bin3c.232', 'bin3c.239', 'bin3c.252', 'bin3c.254', 'bin3c.26', 'bin3c.266', 'bin3c.274', 'bin3c.276', 'bin3c.292', 'bin3c.345', 'bin3c.347', 'bin3c.396', 'bin3c.400', 'bin3c.42', 'bin3c.426', 'bin3c.460', 'bin3c.465', 'bin3c.484', 'bin3c.490', 'bin3c.497', 'bin3c.543', 'bin3c.623', 'bin3c.74', 'bin3c.90', 'bin3c.94']\n"
     ]
    }
   ],
   "source": [
    "# Download supplementary materials from the paper\n",
    "! wget -P ../data https://static-content.springer.com/esm/art%3A10.1038%2Fs41587-021-01130-z/MediaObjects/41587_2021_1130_MOESM3_ESM.xlsx -nc\n",
    "\n",
    "# EDA - How many HQ MAGs based on DAStool definition?\n",
    "df_bickhart = pd.read_excel(\"../data/41587_2021_1130_MOESM3_ESM.xlsx\", 'SupplementaryTable2')\n",
    "df_bickhart.loc[:, \"genome_id\"] = [i.replace(\"_\", \".\") for i in df_bickhart.loc[:, 'HiFiBin']]\n",
    "df_bickhart = df_bickhart.set_index(\"genome_id\", drop=False)\n",
    "complete = df_bickhart.loc[:, \"HiFiBin Completeness\"] > 90\n",
    "contam = df_bickhart.loc[:, \"HifiBin Contamination\"] < 5\n",
    "df_bickhart_HQ = df_bickhart.loc[complete & contam]\n",
    "print(f\"Bickhart et al has a total of {len(df_bickhart)} bins. Based on their methods, {len(df_bickhart_HQ)} are HQ.\")\n",
    "\n",
    "# Caitlin has ran CheckM to all bins. How many HQ MAGs based on CheckM definition?\n",
    "df_bickhart_checkm = pd.read_csv(file_bickhart_checkm, sep=\"\\t\")\n",
    "df_bickhart_checkm.loc[:, \"genome_id\"] = [i.replace(\".contigs\", \"\") for i in df_bickhart_checkm.loc[:, \"Bin Id\"]]\n",
    "df_bickhart_checkm = df_bickhart_checkm.set_index(\"genome_id\", drop=False)\n",
    "complete = df_bickhart_checkm.loc[:, \"Completeness\"] > 90\n",
    "contam = df_bickhart_checkm.loc[:, \"Contamination\"] < 5\n",
    "df_bickhart_checkm_HQ = df_bickhart_checkm.loc[complete & contam]\n",
    "print(f\"After running CheckM on the {len(df_bickhart_checkm)} bins, we get {len(df_bickhart_checkm_HQ)} HQ MAGs.\")\n",
    "\n",
    "# Where does the tools disagree?\n",
    "try:\n",
    "    df_bickhart_HQ.loc[list(df_bickhart_checkm_HQ.index)]\n",
    "except KeyError as e:\n",
    "    print(\"These bins are classified as HQ in CheckM, but not in DAStools:\")\n",
    "    print(ast.literal_eval(e.args[0].replace(\" not in index\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3c6566a3-d869-4090-adae-33cecc6c5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format to BGCflow config\n",
    "df_bickhart = pd.concat([df_bgcflow_template, df_bickhart_checkm_HQ])\n",
    "col = df_bickhart.pop(\"genome_id\")\n",
    "df_bickhart.insert(0, col.name, col)\n",
    "df_bickhart.loc[:, \"source\"] = \"custom\"\n",
    "\n",
    "# To Do: Assign GTDB taxonomy\n",
    "#[i for i in df_gtdb.user_genome if i.startswith(\"bin\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e4c53-286c-4019-9545-e18f4f0a5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bickhart.to_csv(external_table_path / \"df_bickhart_checkm_HQ.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e9fb7-0d05-4fec-a944-48bef9e9c0ee",
   "metadata": {},
   "source": [
    "The selected genomes are then copied to the BGCflow directory for downstream analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3090a265-6f6c-4a0b-8769-cc236b2135d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Paths\n",
    "bickhart_raw_path = Path(\"../data/b3c_hifi_dastool/\")\n",
    "bickhart_data_path = external_data_path / \"Bickhart_et_al\"\n",
    "bickhart_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# copy files to target dir\n",
    "for i in df_bickhart.loc[:, \"genome_id\"]:\n",
    "    item = bickhart_raw_path / f\"flye4.das_DASTool_bins/{i}.contigs.fa.gz\"\n",
    "    dest = bickhart_data_path / f\"{i}.fna\"\n",
    "    if dest.is_file():\n",
    "        pass\n",
    "    else:\n",
    "        if item.is_file():\n",
    "            with gzip.open(item, 'rb') as f_in:\n",
    "                with open(dest, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "        else:\n",
    "            item = bickhart_raw_path / f\"flye4.das_DASTool_bins/{i}.contigs.fa\"\n",
    "            assert(item.is_file())\n",
    "            shutil.copy(item, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7af788-5f23-4e77-82b4-7819f6a35c23",
   "metadata": {},
   "source": [
    "# Dataset from Liu et al (557 genomes)\n",
    "The dataset was kindly provided by the authors here: https://www.dropbox.com/sh/qj4aginbflqmxhq/AAB5INvLNKrGiBtjpRbteYJ7a. The dataset are then downloaded using wget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dfd96-7d1c-49e0-897d-6e4910540f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAG set for the Liu paper (557)\n",
    "! wget -P ../data https://www.dropbox.com/sh/qj4aginbflqmxhq/AAB5INvLNKrGiBtjpRbteYJ7a?dl=0 -nc\n",
    "! mv ../data/AAB5INvLNKrGiBtjpRbteYJ7a\\?dl\\=0 ../data/Liu_et_al.zip\n",
    "! unzip ../data/Liu_et_al.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b5943-91b7-46e9-ae6a-56dcc777c538",
   "metadata": {},
   "source": [
    "The metadata for the genomes are then cleaned to create a list of genomes that will be used in the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c526a32c-49cc-4ace-b3b4-dc3ced0c59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘../data/40168_2021_1155_MOESM2_ESM.xlsx’ already there; not retrieving.\n",
      "\n",
      "Liu et al has 557 MAGs.\n",
      "Out of these, 153 is HQ\n"
     ]
    }
   ],
   "source": [
    "# Download supplementary materials from the paper\n",
    "! wget -P ../data https://static-content.springer.com/esm/art%3A10.1186%2Fs40168-021-01155-1/MediaObjects/40168_2021_1155_MOESM2_ESM.xlsx -nc\n",
    "\n",
    "# Clean Up\n",
    "df_liu = pd.read_excel(\"../data/40168_2021_1155_MOESM2_ESM.xlsx\", sheet_name=2, skiprows=0)\n",
    "print(f\"Liu et al has {len(df_liu)} MAGs.\")\n",
    "\n",
    "# Filter for HQ only\n",
    "complete = df_liu.loc[:, \"Completeness (%)\"] > 90\n",
    "contam = df_liu.loc[:, \"Contamination (%)\"] < 5\n",
    "df_liu_HQ = df_liu.loc[complete & contam]\n",
    "print(f\"Out of these, {len(df_liu_HQ)} is HQ\")\n",
    "\n",
    "df_liu_HQ = pd.concat([df_bgcflow_template, df_liu_HQ])\n",
    "df_liu_HQ.insert(0, 'genome_id', df_liu_HQ.loc[:, \"MAGs\"])\n",
    "df_liu_HQ = df_liu_HQ.drop(columns=[\"MAGs\"])\n",
    "df_liu_HQ.loc[:, \"source\"] = \"custom\"\n",
    "df_liu_HQ.to_csv(external_table_path / \"df_liu_HQ.csv\", index=None)\n",
    "# ! for f in *.fasta; do mv -- \"$f\" \"${f%.fasta}.fna\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b89e3cd-a8fb-49d8-bd34-d1f24b08153d",
   "metadata": {},
   "source": [
    "# Dataset from Christoph et al (73 genomes)\n",
    "The dataset from Christoph et al are publicly available from NCBI: https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJNA449266. The assembly details file: `PRJNA449266_AssemblyDetails.txt` were downloaded, containing the assembly accessions of the study, which then can be downloaded using ncbi-genome-download.\n",
    "\n",
    "HQ-MAGs are selected from the dataset with this definition:\n",
    ">High-quality draft' will indicate that a SAG or MAG is >90% complete with less than 5% contamination\n",
    "\n",
    "The metadata for the genomes are then cleaned to create a list of genomes that will be used in the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e847f352-f9af-447d-ab48-8f9085b05845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘../data/41586_2018_207_MOESM3_ESM.xlsx’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download supplementary materials from the paper\n",
    "! wget -P ../data https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-018-0207-y/MediaObjects/41586_2018_207_MOESM3_ESM.xlsx -nc\n",
    "df_christoph = pd.read_excel(\"../data/41586_2018_207_MOESM3_ESM.xlsx\", sheet_name=0, skiprows=0)\n",
    "\n",
    "# filter for HQ\n",
    "a = df_christoph.loc[:, \"CheckM Completeness %\"] > 90\n",
    "b = df_christoph.loc[:, \"CheckM Contamination %\"] < 5\n",
    "df_christoph = df_christoph[a & b]\n",
    "\n",
    "# Get NCBI accession\n",
    "df_christoph.loc[:, \"ncbi_mapping\"] = [i.split(\"_\", 1)[-1].replace(\"_\", \" \") for i in df_christoph.loc[:, \"Genome\"]]\n",
    "need_cleaning = df_christoph.loc[:, \"ncbi_mapping\"].str.startswith(\"unk\")\n",
    "df_christoph.loc[df_christoph[need_cleaning].index, \"ncbi_mapping\"] = [i.split(\" \")[-1] for i in df_christoph[need_cleaning].loc[:, \"ncbi_mapping\"]]\n",
    "df_christoph_ncbi = pd.read_csv(file_christoph_ncbi, sep=\"\\t\", skiprows=1, index_col=False)\n",
    "df_christoph_ncbi_subset = df_christoph_ncbi[df_christoph_ncbi.loc[:, \"Isolate\"].isin(df_christoph.loc[:, \"ncbi_mapping\"])]\n",
    "df_christoph = df_christoph.merge(df_christoph_ncbi_subset, how=\"left\", left_on=\"ncbi_mapping\", right_on=\"Isolate\")\n",
    "df_christoph = pd.concat([df_bgcflow_template, df_christoph])\n",
    "df_christoph.insert(0, 'genome_id', df_christoph.loc[:, \"# Assembly\"])\n",
    "df_christoph = df_christoph.drop(columns=[\"# Assembly\"])\n",
    "df_christoph.loc[:, \"source\"] = \"ncbi\"\n",
    "df_christoph.to_csv(\"../tables/other_studies/df_christoph.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292195b2-26c4-4ae5-b891-36950cf9b371",
   "metadata": {},
   "source": [
    "Some of these genomes are already used as GTDB reference. These genomes are discarded in the GTDB-tk classify wf as it will return an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ec5bec-c3d9-4a78-88ea-554f47a7a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(file_gtdb_warning, skiprows=1, header=None, sep=\" \").loc[:, 3].to_csv(\"../tables/filter_gtdb.txt\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c757e-5833-4a7b-bc1f-723e29b50f6d",
   "metadata": {},
   "source": [
    "# Dataset from Sharrar et al (374 genomes)\n",
    "\n",
    "The dataset was kindly provided by the authors here: https://figshare.com/ndownloader/files/18105260. The dataset are then downloaded using wget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b1f0b-99f6-4bc4-9dc6-bd348a831670",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -P ../data https://figshare.com/ndownloader/files/18105260 -nc\n",
    "! mv ../data/18105260 ../data/1334_genomes.tar.gz # then untar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d36e9-6e17-4de8-95f9-67f8da29ac45",
   "metadata": {},
   "source": [
    "The metadata for the genomes are then cleaned to create a list of genomes that will be used in the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c011def3-9207-4ae4-9f11-feb50a6a27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download supplementary materials from the paper\n",
    "! wget -P ../data https://journals.asm.org/doi/suppl/10.1128/mBio.00416-20/suppl_file/mbio.00416-20-st002.xlsx -nc\n",
    "\n",
    "# Clean Up\n",
    "df_sharrar = pd.read_excel(\"../data/mbio.00416-20-st002.xlsx\", sheet_name=0, skiprows=0)\n",
    "df_sharrar = df_sharrar[df_sharrar.loc[:, \"MAG draft quality\"] == \"High\"]\n",
    "df_sharrar = pd.concat([df_bgcflow_template, df_sharrar])\n",
    "df_sharrar.insert(0, 'genome_id', df_sharrar.loc[:, \"Genome name\"])\n",
    "df_sharrar = df_sharrar.drop(columns=[\"Genome name\"])\n",
    "df_sharrar.loc[:, \"source\"] = \"custom\"\n",
    "df_sharrar.to_csv(\"../tables/other_studies/df_sharrar.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25065b-70c8-4cb1-8845-c681a5a66544",
   "metadata": {},
   "source": [
    "The selected genomes are then copied to the BGCflow directory for downstream analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e65bc22-df39-4291-9819-c1ae35286f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy files to target dir\n",
    "sharrar_raw_path = Path(\"../data/1334_genomes\")\n",
    "sharrar_data_path = external_data_path / \"Sharrar_et_al\"\n",
    "sharrar_data_path.mkdir(parents=True, exist_ok=True)\n",
    "for i in df_sharrar.loc[:, \"genome_id\"]:\n",
    "    item = sharrar_raw_path / f\"{i}.contigs.fa\"\n",
    "    dest = sharrar_data_path / f\"{i}.fna\"\n",
    "    shutil.copy(item, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af38a4d-5230-457a-95e9-434869c5f5d4",
   "metadata": {},
   "source": [
    "# Downloading dataset from Chen et al\n",
    "The dataset for Chen et al are available from: https://api.mg-rast.org/project/mgp81948?verbosity=full. The genomes can then be fetched using MG-RAST API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3d0f0-ad87-4f69-97df-3c1f75158e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api(api_url, output):\n",
    "    response = requests.get(api_url)\n",
    "    project_metadata = response.json()\n",
    "    with open(output, 'w') as outfile:\n",
    "        json.dump(project_metadata, outfile)\n",
    "    return None\n",
    "\n",
    "get_api('https://api.mg-rast.org/project/mgp81948?verbosity=full', '../data/mgp81948.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62385c-4072-4422-85a4-77edcadd77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/mgp81948.json', \"r\") as f:\n",
    "    study_metadata = json.load(f)\n",
    "    ids = [i[\"metagenome_id\"] for i in study_metadata[\"metagenomes\"]]\n",
    "    for mg_id in ids:\n",
    "        url = f\"https://api.mg-rast.org/download/{mg_id}?file=299.1\"\n",
    "        ! wget -O ../data/chen/{mg_id}.fna {url}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b031dae-e443-4dd5-a059-0e3b349ac98e",
   "metadata": {},
   "source": [
    "The metadata for the genomes cam be accessed from https://www.frontiersin.org/articles/10.3389/fmicb.2020.01950/full#supplementary-material. The metadata are then cleaned to create a list of genomes that will be used in the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "aefc6748-4753-4b4d-b4c1-39d818096b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download supplementary materials from the paper\n",
    "df_chen_metadata = pd.read_excel(file_chen_metadata, sheet_name=0, skiprows=5)\n",
    "\n",
    "with open(\"../data/mgp81948.json\", \"r\") as file:\n",
    "    chen_metadata = json.load(file)\n",
    "df_chen = pd.DataFrame.from_dict([i for i in chen_metadata[\"metagenomes\"]])\n",
    "df_chen = pd.concat([df_bgcflow_template, df_chen])\n",
    "df_chen.insert(0, 'genome_id', df_chen.loc[:, \"metagenome_id\"])\n",
    "df_chen = df_chen.drop(columns=[\"metagenome_id\"])\n",
    "df_chen.loc[:, \"source\"] = \"custom\"\n",
    "df_chen.to_csv(\"../tables/other_studies/df_chen.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
