#' List antismash .json outputs
#' Retrieve .json files two levels deep in a directory with antiSMASH output folders
#' @param antismash_dir Path for a directory containing one or more antiSMASH output directories
#' @return Returns a character vector with paths to all .json antiSMASH files
list_jsons <- function(antismash_dir){
  output_dirs <- list.files(path = antismash_dir, full.names = TRUE)
  list.files(output_dirs, pattern = ".json$", full.names = TRUE)
}

#' Extract features from an antiSMASH json#'
#' @param antismash_json Path to an antiSMASH .json file 
#' @param feature_types Character vector with the types of features to extract
#' @return A list object with an element per record, containing the selected features
get_features <- function(antismash_json, feature_types = c("region", "aSModule")){
  records <- read_json(antismash_json)$records 
  set_names(records, map_chr(records, "id")) %>%
    map("features") %>%
    map(~keep(.x, ~.[['type']] %in% feature_types)) %>% 
    compact() 
}

#' Creates a dataframe with region information from antiSMASH data
#' @param features List object generated by `get_features`
#' @return A tibble where each where each region is an observation 
get_regions <- function(features){
  regions <-  map(features, ~keep(.x, ~.['type'] == "region"))
  if(is_empty(regions) == FALSE) {
    result <- regions %>% map(~map_df(.x, ~tibble(
    location = .[['location']], 
    type = .[['type']], 
    contig_edge = as.logical(.[['qualifiers']][['contig_edge']]), 
    product = list(.[['qualifiers']][['product']]), 
    region_number = as.integer(.[['qualifiers']][['region_number']])))) %>%
    bind_rows(.id = 'contig') %>%
    select(-type) %>%
    mutate(product = map(product, ~as.character(.x)),
           product = map(product, sort), 
           bgc_id = paste0(contig, ".region", str_pad(
             region_number, width = 3, pad = '0'))) %>%
      select(-region_number)
  } else {result <- NULL
  }
  return(result)
}
 
#' Creates a dataframe with module information from antiSMASH data
#' @param features List object generated by `get_features`
#' @return A tibble where each where each region is an observation
get_modules <- function(features){
  features %>%
    map(~keep(.x, ~.['type'] == "aSModule")) %>%
    compact() %>%
    map(~map_df(.x,  ~tibble(
      location = .[['location']],
      complete = case_when(
        'incomplete' %in% names(.[['qualifiers']]) ~ FALSE, 
        'complete' %in% names(.[['qualifiers']]) ~ TRUE, 
        TRUE ~ FALSE),
      type = as.character(.[['qualifiers']][['type']]), 
      iterative = if_else('iterative' %in% names(.[['qualifiers']]), TRUE, FALSE))))%>%
    bind_rows(.id = 'contig')
}

#' Parses an antismash .json and returns two tibbles, for regions and modules
#' @param antismash_json Path to .json file
#' @return A list with two tibbles, the first for regions, the second for modules
get_dataframes_from_antismash <- function(antismash_json){
  features <- get_features(antismash_json)
  regions <- get_regions(features)  
  modules <- get_modules(features)
  # This way I avoid parsing each file twice, which is the most time consuming part
  return(list(regions = regions, modules = modules))
}
  
#' Parses a directory with antiSMASH output folders
#' @param antismash_dir Directory containing antiSMASH output folders
#' @param cores Integer, number of cores to use in parallel 
#' @return A list containing two tibbles, one for the regions, other for the modules
parse_study <- function(antismash_dir){
 # cl <- makeForkCluster(nnodes = cores)
  antismash_jsons <- list_jsons(antismash_dir)
  genome_ids <- str_match(basename(antismash_jsons), "(^.+)\\.json")[,2]
  features_lists <- sapply(antismash_jsons, get_dataframes_from_antismash, simplify = FALSE)
  names(features_lists) <- genome_ids
  regions <- bind_rows(map(features_lists, "regions"), .id = "genome_id")
  modules <- bind_rows(map(features_lists, "modules"), .id = "genome_id")
  return(list(regions = regions, modules = modules))
}

#' Imports BiG-SCAPE's info from clustering files
#'
#' @param bigscape_dir Directory with bigscape output
#'
#' @return A tibble in "long format" with BGC ids , its classes, cutoffs and GCFs

import_bigscape <- function(bigscape_dir){
  
  clustering_files <- 
    list.files(
      path = bigscape_dir,
      pattern = "clustering",
      recursive = TRUE, 
      full.names = TRUE) 
  
  sapply(clustering_files, 
         read_tsv, 
         col_types = 'cc', 
         simplify = FALSE) %>%
    set_names(basename(clustering_files)) %>%
    bind_rows(.id = "table") %>%
    mutate(cutoff = as.numeric(str_match(table, "clustering_c(.+)\\.tsv")[,2]), 
           class = str_match(table, "(^.+?)_clustering")[,2]) %>%
    select(-table) %>%
    set_names(c('bgc_id', 'GCF', 'cutoff', 'class')) %>%
    distinct()
  
}  

